<section xml:id="section-extrema">
  <title>Extrema</title>
  <subsection xml:id="subsection-extreme-values">
    <title>Extreme Values</title>
    <p>
      I start with the definition of extreme values. This extends the
      definition from Calculus I for single variable functions. 
    </p>
    <definition>
      <statement>
        <p>
          Let <m>f: \RR^n \rightarrow \RR</m> be a differentiable
          scalar function. Then a point <m>p \in \RR^n</m> is a local
          maximum of <m>f</m> is there exists <m>\epsilon > 0</m> such
          that <m>f(p) \geq f(q)</m> for all <m>q \in B(p,
          \epsilon)</m>. Similarly, a point <m>p \in \RR^n</m> is a
          local minimum of <m>f</m> is there exists <m>\epsilon >
          0</m> such that <m>f(p) \leq f(q)</m> for all <m>q \in B(p,
          \epsilon)</m>.
        </p>
      </statement>
    </definition>
    <p>
      This definition clarifies that if a point is a minimum or
      maximum, is it is a peak or valley in all directions. It needs
      to be above or below nearby function values in any direction in
      the domain. In two variables, I also want to classify a new
      kind of extreme value.
    </p>
    <definition xml:id="def-saddle-point">
      <statement>
        <p>
          Let <m>f: \RR^2 \rightarrow \RR</m> be a differentiable
          function. Then a point <m>p \in \RR^n</m> is a saddle point
          of <m>f</m> if there there are two unit directions <m>u</m>
          and <m>v</m> in <m>\RR^2</m> and <m>\epsilon > 0</m> such
          that <m>f(p \pm \delta u) \geq f(p)</m> and <m>f(p \pm
          \delta v) \leq f(q)</m> for all <m>\delta \lt \epsilon</m>.
        </p>
      </statement>
    </definition>
    <p>
      A saddle point is both a minimum and a maximum: it is a minimum
      in some direction <m>v</m> and a maximum in some other direction
      <m>u</m>. It is called a saddle point for the saddle-like shape
      that results from this situation for graphs of two-variable
      funcitons. For higher dimensions, a saddle point is any point
      which is a maximum is some number of directions and a minimum is
      all other direction (for some linearly independent set of
      directions in the domain).
    </p>
  </subsection>
  <subsection xml:id="subsection-finding-extrema">
    <title>Finding Extrema</title>
    <p>
      A key obervation from Calculus I is that maxima and minima were
      found when <m>f^\prime(x) = 0</m>. (Though <m>f^\prime =0</m>
      didn't guarantee an extreme value, as in the example of <m>f(x)
      = x^3</m> at <m>x=0</m>).
    </p>
    <proposition>
      <statement>
        <p>
          Let <m>f: \RR^n \rightarrow \RR</m> be a differential
          function. Assume <m>f</m> has a minimum, maximum, saddle
          point, or other unclassified extremum at <m>p \in \RR^n</m>.
          Then <m>\nabla f (p) = 0</m>.
        </p>
      </statement>
    </proposition>
    <p>
      The gradient measures the direction of greatest change. At a
      minimum, maximum or saddle point, there is no such direction, so
      the gradient is zero. As with single-variable calculus, the
      implication is only one direction. As with single variable
      functions, there may be points where the gradient is zero but the
      point is neither a minimum, maximum nor saddle point.
    </p>
    <p>
      The gradient is the vector of partial derivatives, so it is
      important to note that <em>all</em> the partial derivatives must
      vanish. If only some of them vanish, the graph may have interesting
      behaviour, but the point is not a maximum or minimum.
    </p>
  </subsection>
  <subsection xml:id="subsection-extrema-examples">
    <title>Examples</title>
    <figure xml:id="figure-3d-graph5">
      <caption>
        The function <m>f(x,y) = x-y^2+3</m>.
      </caption>
      <image xml:id="figure44" width="90%">
        <asymptote>
          import graph3;
          import palette;
          size(14cm,7cm,IgnoreAspect);
          currentprojection=orthographic(-1,1,0.5);

          real f(pair z) {return (z.x - (z.y)^2+3)*(1/3);}

          limits((-2,-1.9,-2),(2,2,1));

          xaxis3("$x$",Bounds(Both,Value),OutTicks(Step=1));
          yaxis3("$y$",Bounds(Both,Value),OutTicks(Step=1));

          surface s=surface(f,(-2,-2),(2,2),100,Spline);

          pen[] pens=mean(palette(s.map(zpart),Gradient(green,blue)));

          draw(s,pens);
        </asymptote>
      </image>
    </figure>
    <example>
      <statement>
        <p>
          Consider the function <m>f(x,y) = x-y^2+3</m>,
          shown in Figure <xref ref="figure-3d-graph5" />. The
          <m>y</m> partial is <m>f_y(x,y) = -2y</m>, which vanishes
          everywhere along the <m>x</m> axis (when <m>y=0</m>).
          However, the other partial is <m>f_x = 1</m>, which never
          vanishes. This means that all points <m>(x,0)</m> are
          potentially critical in <m>y</m> but not in <m>x</m>. This
          function is a ascending/decending ridge (with slope
          <m>1</m>) above the <m>x</m> axis. 
        </p>
      </statement>
    </example>
    <figure xml:id="figure-3d-graph6">
      <caption>
        The function <m>f(x,y) = \cos (x+y)</m>
      </caption>
      <image xml:id="figure45" width="90%">
        <asymptote>
          import graph3;
          import palette;
          size(12cm,6cm);
          currentprojection=orthographic(-1,0.6,0.3);

          real f(pair z) {return cos(z.x+z.y)+1/2;}

          limits((-5,-4.9,-2),(5,5,2));

          xaxis3("$x$",Bounds(Both,Value),OutTicks(Step=2));
          yaxis3("$y$",Bounds(Both,Value),OutTicks(Step=2));

          surface s=surface(f,(-5,-5),(5,5),100,Spline);

          pen[] pens=mean(palette(s.map(zpart),Gradient(green,blue)));

          draw(s,pens);
        </asymptote>
      </image>
    </figure>
    <example>
      <statement>
        <p>
          Since scalar fields are defined in several dimensions, the
          collection of maxima/minima can be complicated sets.  The
          function <m>f(x,y) = \cos (x+y)</m>, shown in Figure <xref
          ref="figure-3d-graph6" /> has a maximum whenever
          <m>x+y</m> is an even multiple of <m>\pi</m>. Each of those
          sets is a whole line, <m>x+y=0</m>, <m>x+y = 2\pi</m> and so
          on. For functions of two variables, its easy to have lines
          or curves of maximum or minimum points. In higher
          dimensions, there can be surfaces or hypersurfaces of
          maximum or minimum points.
        </p>
      </statement>
    </example>
    <p>
      I want to classify critical points: points where <m>\nabla f =
      0</m>. I can do this informally by looking at each variable
      individually. If the point is a maximum in all of <m>x_1, x_2,
      \ldots, x_n</m>, then it is a maximum according to our
      definition above. Likewise, if it is a minimum in all the
      variables, it is a minimum. If it is a maximum in some of the
      variables and a minimum in others, it is a saddle point.
      However, if even one of the variables has no max/min behvaiour
      (like <m>f(x) = x^3</m> at <m>x=0</m>), then the point is
      neither a maximum, minimum nor saddle point.
    </p>
  </subsection>
  <subsection xml:id="subsection-hessians">
    <title>Hessian Matrices</title>
    <p>
      This informal approach is reasonable, but it would be nice to
      have a more formal method for determining the behaviour. In
      single variable calculus, a formal method is the
      second-derivative test.  If <m>a</m> is a critical point, then
      it is a maximum if <m>f^{\prime \prime}(a)</m> is negative, a
      minimum if <m>f^{\prime \prime}(a)</m> is positive, and the test
      is inconclusive if <m>f^{\prime \prime}(a) = 0</m>.
    </p>
    <p>
      I'd like to generalize this, but there are many second
      derivatives: all of the possible mixed and non-mixed second
      partials. One way I can organize all these second partials is
      in a matrix.
    </p>
    <definition>
      <statement>
        <p>
          The matrix of all the second partial derivatives of a scalar
          function <m>f</m> is called the <term>Hessian
          Matrix</term>.
        </p>
      </statement>
    </definition>
    <p>
      Here is the Hessian matrix for <m>f(x,y)</m> in two variables.
      <me>
        \begin{pmatrix} 
          \dfrac{\del^2 f}{\del x^2} \amp \dfrac{\del^2 f}{\del y \del
          x} \\ 
          \dfrac{\del^2 f}{\del x \del y} \amp \dfrac{\del^2 f}{\del
          y^2} 
        \end{pmatrix}
      </me>
    </p>
    <p>
      Here is the Hessian matrix for <m>f(x,y,z)</m> in three variables.
      <me>
        \begin{pmatrix} 
          \dfrac{\del^2 f}{\del x^2} \amp \dfrac{\del^2 f}{\del y \del
          x} \amp \dfrac{\del^2 f}{\del z \del y} \\[1em]
          \dfrac{\del^2 f}{\del x \del y} \amp \dfrac{\del^2 f}{\del
          y^2} \amp \dfrac{\del^2 f}{\del z \del y} \\[1em]
          \dfrac{\del^2 f}{\del x \del z} \amp \dfrac{\del^2 f}{\del y
          \del z} \amp \dfrac{\del^2 f}{\del z^2} 
        \end{pmatrix} 
      </me>
    </p>
    <p>
      Note that the Hessian is not the Jacobian matrix from before;
      that matrix had only first derivatives. The Hessian matrix only
      applies to single valued function (outputs in <m>\RR</m>), is
      always square, and lists all the possible second partials.
    </p>
    <p>
      The Hessian matrix captures all of the information about the
      second derivative of this function, but it is often too unwieldy
      to be used to determine the behaviour of critical points.
      However, I can use a useful tool from linear algebra to get
      specific information out of a matrix: the determinant. Let
      <m>D</m> be the determinant of the Hessian matrix. For
      <m>f(x,y)</m>, <m>D</m> has the following form (using Clairaut's
      theorm to simplify the mixed partials).
      <me>
        D = \frac{\del^2 f}{\del x^2} \frac{\del^2 f}{\del y^2} -
        \left( \frac{\del^2 f}{\del x \del y} \right)^2
      </me>
    </p>
    <p>
      For functions of two variables, the determinant of the Hessian
      determines the behaviour. 
    </p>
    <proposition>
      <statement>
        <p>
          Let <m>f: \RR^2 \rightarrow \RR</m> be a <m>C^2</m> scalar
          field and let <m>(a,b)</m> be a critical point. Then there
          are four cases.
          <ul>
            <li>
              <p>
                If <m>D(a,b) > 0</m> and <m>\frac{\del^2 f}{\del x^2}
                (a,b) > 0</m> then the critical point is a minimum.
              </p>
            </li>
            <li>
              <p>
                If <m>D(a,b) > 0</m> and <m>\frac{\del^2 f}{\del x^2}
                (a,b) \lt 0</m> then the critical point is a maximum.
              </p>
            </li>
            <li>
              <p>
                If <m>D(a,b) \lt 0</m> then the critical point is a
                saddle point.
              </p>
            </li>
            <li>
              <p>
                If <m>D(a,b) = 0</m> then the test is inconclusive.
              </p>
            </li>
          </ul>
        </p>
      </statement>
    </proposition>
    <p>
      This proposition can be generalized to higher dimensions, but it
      requires more machinery from linear algebra, namely eigenvalues.
      Clairaut's theorem means that the Hessian is always a symmetric
      matrix, so it always has a maximal set of real eigenvalues. The
      general proposition classifies the extrema using those
      eigenvalues.
    </p>
    <proposition>
      <statement>
        <p>
          Let <m>f: \RR^n \rightarrow \RR</m> be a <m>C^2</m> scalar
          field with <m>H</m> its Hessian matrix. Let <m>u \in
          \RR^n</m> be a critical point and let <m>H(u)</m> be the
          Hessian evaluated at the point <m>u</m>. Then there are four
          cases.
          <ul>
            <li>
              <p>
                If <m>H(u)</m> is not invertible (has determinant 0,
                has 0 as an eigenvalue), then the test is
                inconclusive.
              </p>
            </li>
            <li>
              <p>
                If all the eigenvalues of <m>H(u)</m> are positive,
                then the critical point is a local minimum.
              </p>
            </li>
            <li>
              <p>
                If all the eigenvalues of <m>H(u)</m> are negative,
                then the critical point is a local maximum.
              </p>
            </li>
            <li>
              <p>
                If the eigenvalues of <m>H(u)</m> are a mix of
                positive and negative, then the critical point is a
                saddle point or a higher dimensional analogue mixing
                minima in some directions and maxima in others. 
              </p>
            </li>
          </ul>
        </p>
      </statement>
    </proposition>
  </subsection>
  <subsection xml:id="subsection-hessian-examples">
    <title>Examples</title>
    <figure xml:id="figure-3d-graph7">
      <caption>
        The function <m>f(x,y) = x^2+2y^2 - 4x + 4y + 6</m>.
      </caption>
      <image xml:id="figure46" width="90%">
        <asymptote>
          import graph3;
          import palette;
          size(12cm,5cm);
          currentprojection=orthographic(-1,0.6,0.5);

          real f(pair z) {return ((z.y)^2*(z.x)^2 + (z.y)^2)*(1/20);}
          
          limits((-2,-2,0),(2,1.9,2));

          xaxis3("$x$",Bounds(Both,Value),OutTicks(Step=1));
          yaxis3("$y$",Bounds(Both,Value),OutTicks(Step=1));
          
          surface s=surface(f,(-2,-2),(2,2),100,Spline);

          pen[] pens=mean(palette(s.map(zpart),Gradient(green,blue)));
          
          draw(s,pens);
        </asymptote>
      </image>
    </figure>
    <example>
      <statement>
        <p>
          <m>f(x,y) = x^2 y^2 + y^2</m> is shown in Figure <xref
          ref="figure-3d-graph7" />.  I calculate the gradient to find
          the potential extrema. Then I calculate the second partials
          and the determinant of the Hessian matrix to classify the
          extrema. 
          <md>
            <mrow>
              \frac{\del f}{\del x} \amp = 2xy^2 
            </mrow>
            <mrow>
              \frac{\del f}{\del y} \amp = 2x^2y + 2y 
            </mrow>
            <mrow>
              \nabla f(x,y) \amp = 0 \implies (x,y) = (a,0)
              \forall a \in \RR
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x^2} \amp = 2y 
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del y^2} \amp = 2x^2 + 2 
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x \del y} \amp = 4xy 
            </mrow>
            <mrow>
              D \amp = (2y)(2x^2+ 2) - 16x^2 y^2 
            </mrow>
            <mrow>
              \amp = 4yx^2 + 4y - 16x^2 y^2 \implies D(a,0) = 0 
            </mrow>
          </md>
        </p>
        <p>
          At all the critical points <m>(a,0)</m>, the second
          derivative test has <m>D=0</m>, which is inconclusive. I
          have to investigate directly. I can see that <m>f(a,0) =
          0</m>. But <m>f(a,b)</m> for <m>b</m> any small non-zero
          nubmer takes the value <m>a^2 b^2 + b^2</m>, which is always
          positive. Therefore, I can conclude that all the critical
          points <m>(a,0)</m> are local minima. In Figure <xref
          ref="figure-3d-graph7" />, I can see that all
          along the <m>y</m> axis the values stay at <m>0</m>, which
          is the lowest output of the function.
        </p>
      </statement>
    </example>
    <figure xml:id="figure-3d-graph8">
      <caption>
        The function <m>f(x,y) = x^2 + 2y^2 - 4x + 4y + 6</m>.
      </caption>
      <image xml:id="figure47" width="90%">
        <asymptote>
          import graph3;
          import palette;
          size(12cm,5cm,IgnoreAspect);
          currentprojection=orthographic(1,0.6,0.5);

          real f(pair z) {return ((z.x)^2 + 2*(z.y)^2 -4*z.x + 4*z.y + 6);}

          limits((1,-2,0),(3,-0.1,4));

          xaxis3("$x$",Bounds(Both,Value),OutTicks(Step=0.5));
          yaxis3("$y$",Bounds(Both,Value),OutTicks(Step=0.5));

          surface s=surface(f,(1,-2),(3,0),100,Spline);

          pen[] pens=mean(palette(s.map(zpart),Gradient(green,blue)));

          draw(s,pens);
        </asymptote>
      </image>
    </figure>
    <example>
      <statement>
        <p>
          <m>f(x,y) = x^2 + 2y^2 - 4x + 4y + 6</m> is shown in Figure 
          <xref ref="figure-3d-graph8" />.  I calculate the gradient
          to find the potential extrema. Then I calculate the second
          partials and the determinant of the Hessian matrix to
          classify the extrema. 
          <md>
            <mrow>
              \frac{\del f}{\del x} \amp = 2x-4
            </mrow>
            <mrow>
              \frac{\del f}{\del y} \amp = 4y+4
            </mrow>
            <mrow>
              \nabla f(x,y) \amp = 0 \implies (x,y) = (2,-1)
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x^2} \amp = 2 > 0
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del y^2} \amp = 4 > 0
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x \del y} \amp = 0
            </mrow>
            <mrow>
              D \amp = 8 > 0
            </mrow>
          </md>
        </p>
        <p>
          The point <m>(2,-1)</m> is a local minimum.
        </p>
      </statement>
    </example>
    <figure xml:id="figure-3d-graph9">
      <caption>
        The function <m>f(x,y) =\frac{8}{3}x^3 + 4y^3 - x^4 - y^4</m>.
      </caption>
      <image xml:id="figure48" width="90%">
        <asymptote>
          import graph3;
          import palette;
          size(12cm,7cm,IgnoreAspect);
          currentprojection=orthographic(-1,-0.6,0.5);

          real f(pair z) {return
            ((8/3)*(z.x)^3+4*(z.y)^3-(z.x)^4-(z.y)^4)/6;}

          limits((-1,-1,-2),(3,4,6));

          xaxis3("$x$",Bounds(Both,Value),OutTicks(Step=1));
          yaxis3("$y$",Bounds(Both,Value),OutTicks(Step=1));

          surface s=surface(f,(-1,-1),(3,4),100,Spline);

          pen[] pens=mean(palette(s.map(zpart),Gradient(green,blue)));

          draw(s,pens);
        </asymptote>
      </image>
    </figure>
    <example>
      <statement>
        <p>
          <m>f(x,y) = \frac{8}{3} x^3 + 4y^3 - x^4 - y^4</m> is shown
          in Figure <xref ref="figure-3d-graph9" />.  I calculate the
          gradient to find the potential extrema. (I have to solve a
          non-linear system of equations to find these critical
          points, which I haven't shown here.)  Then I calculate the
          second partials and the determinant of the Hessian matrix to
          classify the extrema. 
          <md>
            <mrow>
              \frac{\del f}{\del x} \amp = 8x^2 - 4x^3 = 4x^2 (2-x)
            </mrow>
            <mrow>
              \frac{\del f}{\del y} \amp = 12y^2 - 4y^3 = 4y^2 (3-y)
            </mrow>
            <mrow>
              \nabla f(x,y) \amp = 0 \implies (x,y) = (0,0), (0, 3),
              (2, 0), (2,3)
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x^2} \amp = 16x - 12x^2 = 3x(4-3x)
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del y^2} \amp = 24y - 12y^2 = 12(2-y)
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x \del y} \amp = 0
            </mrow>
            <mrow>
              D \amp = 48xy (4-3x)(2-y)
            </mrow>
            <mrow>
              D(0,0) \amp = 0 
            </mrow>
            <mrow>
              D(0,3) \amp = 0 
            </mrow>
            <mrow>
              D(2,0) \amp = 0 
            </mrow>
            <mrow>
              D(2,3) \amp > 0 
            </mrow>
            <mrow>
              \frac{\del^2 f}{\del x^2} (2,3) \amp \lt  0
            </mrow>
          </md>
        </p>
        <p>
          The point <m>(2,3)</m> is a local maximum, but the test is
          inconclusive at all other points. As can be seen in Figure 
          <xref ref="figure-3d-graph9" />, there is a maximum
          above <m>(2,3)</m>. At the other three critical points, I
          can observe a momentary flattening of the graph, but there
          are neither maxima, minima, nor saddle points. The zero
          Hessian for these points makes sense; they are like the
          critical point at <m>x=0</m> of the cubic <m>f(x) = x^3</m>,
          which has a zero derivative, but no extremum.
        </p>
      </statement>
    </example>
    <example xml:id="example-box-sphere">
      <statement>
        <p>
          I'll try a more geometric optimization problem: what is the
          largest rectangular prism that can fit in a sphere of radius
          <m>r</m>? I'll assume that the prism is centrally located
          in the sphere, which means that its shape is entirely
          determined by one of its vertices on the edge of the sphere.
          If that vertex is <m>(x,y,z)</m>, then the volume of the
          prism is <m>2x \times 2y \times 2z</m>.
        </p>
        <p>
          I'd like to work in spherical coordinates instead of
          <m>x</m>, <m>y</m> and <m>z</m>. The radius <m>r</m> is
          fixed, but <m>\theta</m> (longitude) and <m>\phi</m>
          (colatitude) will vary.
          <md>
            <mrow>
              h \amp = 2r \cos \phi
            </mrow>
            <mrow>
              w \amp = 2r \sin \phi \cos \theta
            </mrow>
            <mrow>
              l \amp = 2 r \sin \phi \sin \theta
            </mrow>
            <mrow>
              V \amp = hwl = 8r^3 \cos \phi \sin^2 \phi \cos \theta
              \sin \theta = 4 r^3 \sin (2\theta) (\cos \phi - \cos^3
              \phi)
            </mrow>
          </md>
        </p>
        <p>
          Then I can optimize the function <m>V(\theta, \phi)</m>.
          <md>
            <mrow>
              \frac{\del V}{\del \phi} \amp = 4r^3 \sin (2\theta) (-
              \sin \phi + 3 \cos^2 \phi \sin \phi)
            </mrow>
            <mrow>
              \frac{\del V}{\del \theta} \amp = 8r^3 \cos 2 \theta
              (\cos \phi - \cos^3 \phi)
            </mrow>
            <mrow>
              \nabla V \amp = 0 \implies (\phi, \theta) = \left(
              \arccos \frac{1}{\sqrt{3}}, \frac{\pi}{4} \right)
            </mrow>
            <mrow>
              V \amp = 4t^3 \sin \frac{\pi}{2} \left(
              \frac{1}{\sqrt{3}} - \frac{1}{3\sqrt{3}} \right) =
              \frac{8r^3}{3\sqrt{3}}
            </mrow>
          </md>
        </p>
        <p>
          I didn't do the calcluation, but it is reasonable to check
          that the critical point represents a maximum. The resulting 
          area is the area of cube of side length
          <m>\frac{2r}{\sqrt{3}}</m>, which seems, intuitively, like
          the right kind of length.
        </p>
      </statement>
    </example>
  </subsection>
  <subsection xml:id="subsection-global-extrema">
    <title>Global Extrema</title>
    <p>
      The above analysis was all about local maxima and minima. I
      can also ask for global maxima and minima. Like the single
      variable case, I do this by looking at all the local extrema as
      well as the boundary. The maximum or minimum might be a
      boundary point which is not a critical point. There is an
      existence proposition, which relies on the topology of the
      domain.
    </p>
    <proposition>
      <statement>
        <p>
          Let <m>C</m> be closed set in <m>\RR^n</m> and <m>f: C
          \rightarrow R</m>. Then <m>f</m> has at least one global
          maximum and at least one global minimum, either at a local
          maximum/minimum or on its boundary.
        </p>
      </statement>
    </proposition>
    <p>
      In general, finding the maximum and minimum on the boundary can
      be quite difficult. 
    </p>
  </subsection>
</section>
